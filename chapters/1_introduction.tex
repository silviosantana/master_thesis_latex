% ----------------------------------------------------------
% Introduction
% ----------------------------------------------------------
\chapter{Introduction}

Embedded Systems and \textit{Systems-on-Chip}~(SoC) are in the center of technological transformation of the modern world. \textit {Internet-of-Things}~(IoT), Industry 4.0, and Smart Systems are some growing markets that evidence these transformations and new design challenges. They reflect the rising complexity of these systems under different perceptions, such as power consumption, occupied area, scalability, and portability. In other words, this technological transformation expose an increasing demand for highly optimized systems, and therefore optimized processors. On the other hand, optimizing processors highlights an important concept of hardware design: \textit{Functional Safety}. This is because the more optimizations in a system, the more prone to error the design process becomes. Consequently, methods for hardware design verification also need to improve.

In the last decades, methods for hardware design have been based mainly on \textit{Hardware Design Languages}~(HDL), such as VHDL and Verilog, at the \textit{Register Transfer Level}~(RTL) \cite{paper-pdd}. For most cases, the RTL design represents the reference model for the system, or “\textit{golden model}”, and it is derived directly from specifications that are, in most cases, described in diagrams, or even in natural language. Traditional techniques for verification of digital designs include simulation with test benches and assertions \cite{paper-symbolic}. Considering the mentioned increase on the complexity of processors and SoCs, these verification methods become more costly and time consuming. Writing test benches to cover the specified scenarios, running simulations and analysing wave forms are some examples of that. \SSREP{These techniques are also known as “\textit{bug hunting}”, because they do not guarantee a \textit{bug-free} design.}{In addition, there is no formalism associated to these techniques that can guarantee that the design fully corresponds to the specifications.} \TLSAY{these techniques are not known as "bug hunting". They are the most used approach to verify a design} 

A higher-level description of the design, for instance the \textit{Electronic System Level}~(ESL), can be developed using programming languages like \textit{C++} associated with some special libraries such as \textit{SystemC}. Some advantages of ESL models are the \SSDEL{relatively} \TLSAY{relativ to what?} faster simulations\SSINS{, when compared to RTL simulations}, achieved by modelling communication as transactions instead of a cycle-accurate simulation, and well-established debugging tools. Furthermore, there are \textit{High-Level Synthesis}~(HLS) tools which allow these high-level descriptions to be used to generate the implementation of the design. Even though HLS tools have improved in the past years, it is still limited to be applied to some specific domains like signal processing algorithms \cite{paper-pdd}. 

One way to improve efficiency in the verification process is applying \textit{formal verification}~(FV) methods. In contrast to the conventional verification approach with simulation, FV methods uses properties to describe the behavior of the system and to check its correctness\SSINS{, and it can provide analytical proof that the design behaves according to the specifications.} \SSDEL{It also allows to overcome the \textit{semantic gap} problem. The term semantic gap, applied to the hardware development world, refers to a gap between the specification of the system and its implementation,} \SSDEL{i.e. the implemented design does not fully cover the specified behaviour}\SSDEL{i.e. there exists no well defined semantics between high-level abstract description, e.g. ESL, and lower-level description, e.g. RTL, that can guarantee an equivalent behavior.} \TLSAY{not correct some implementation details (like timing and bit-wise operations are missing. It can still be correct. You just don't know.}. However, as previously stated, the specifications are in their majority described in natural language or in terms of diagrams. Thus, the System-Level models, e.g. ESL models, \TLSAY{they cant be used for validation because of the semantic gap ... I think they are either just as fast prototypes or for architectural exploration} are kept as \SSINS{fast} prototypes used for \SSINS{architectural exploration and early evaluation of target design.} \SSDEL{validation of functional and non-functional requirements}. In this case, there is no \SSREP{formal connection}{well-defined formal relationship} between RTL and system-level implementation\SSINS{, problem known as \textit{semantic gap}}. Therefore, there is no guarantee that the RTL and ESL models are compatible.

\section*{Motivation}

In \cite{paper-pdd}, a new method for RTL design, called \textit{Property-Driven Design}~(PDD), is proposed. This method is inspired by \textit{Test-Driven Development}~(TDD), an approach used in software development. In contrast to the \textit{V}-model, where testing is done closer to the end of the design process, TDD brings testing to the start of the development process. For that purpose, test cases are created even before the software product itself. This allows to find bugs in the software at earlier stages of the development process. Therefore, correcting the bugs is cheaper than it would be at later stages. Similarly, PDD is intended to bring verification to earlier stages of the design process using formal verification. In this method, a high-level description of the system is used to generate properties that should be refined concomitantly with the RTL implementation. In the end, an RTL design is achieved along with a set of properties that proves its correct behaviour. Additionally, the methodology guarantees that the obtained RTL design corresponds to the initial ESL model. As a result, both can be used as the golden model.

In order to apply the PDD methodology, the high-level model should be written with a subset of the SystemC \cite{lib-systemc} library, called \textit{SystemC-PPA}. The authors in \cite{paper-pdd} created a tool, called DeSCAM \cite{descam}, that reads a SystemC-PPA compliant model and automatically generates a set of properties. As help for the designer, an RTL template that can be used as a start point of the \textit{implementation-refinement} process can be generated.

Even though the methodology works well for sequential models, it is not easily suitable for pipelined processors, due their concurrent behaviour. The SystemC-PPA model is implemented as a sequential model. Therefore, the properties will inherit this sequential behaviour and it will not be able to reflect the concurrent pipeline behaviour. This will cause the hardware designer to have an extra effort to refine these properties to fit the pipeline, or to modify the SystemC-PPA model to simulate the pipelined behaviour. In both cases, the extra effort for the hardware designer mitigates the advantages of the PDD method.

In this work, an algorithm to generate Pipeline Properties using the PDD method is proposed. The algorithm adds an extra step to the PDD process when dealing with pipelined processors design. The properties generated from the sequential SystemC-PPA compliant model are applied to the Pipeline Property Algorithm, which converts these properties into \textit{Pipeline Properties}. Then, the hardware designer can start the \textit{implement-refine} process without extra work.

In order to evaluate the proposed Pipeline Algorithm, a case study was conducted with the RI5CY core. This processor is an open-source implementation based on the RISC-V instruction set architecture (ISA), and it is powered by the PULP Platform \cite{pulp}. A SystemC-PPA compliant model for the RI5CY processor was implemented, and the proposed Pipeline Algorithm was used to generate the Pipeline Properties. In this case study, the RTL implementation is already provided, and the Pipeline Properties should hold for this implementation after the refinement process. In addition, sequential properties were manually written, classical Formal Verification process, from the RTL model. These sequential properties are then used for comparison with the generated Pipeline Properties.

This work is organized as follows. The background in Chapter~\ref{chapter:backgroung} introduces the concept of Formal Verification of digital designs, and an overview of the PDD methodology proposed in \cite{paper-pdd}. Chapter~\ref{chapter:pipeline} discusses verification of pipelined processors. It starts with an introduction to pipeline, presents an overview of property checking applied to pipelined processors, the \SSQED{}\cite{paper-symbolic} approach for completeness, and an insight of the PDD flow applied to design of pipelined processor. Chapter~\ref{chapter:algorithm} presents how to extend the PDD flow for pipelined processors, and proposes an algorithm for generating a pipeline property set. A plugin implementation is also proposed to help the designer creating a setup for the \SSQED{} properties check. Chapter~\ref{chapter:ri5cy} presents the case study where the extended PDD flow and the Pipeline Algorithm are applied to the RI5CY core. The experimental results for the case study are presented in Chapter~\ref{chapter:results} followed by the conclusion in Chapter~\ref{chapter:conclusion}.




