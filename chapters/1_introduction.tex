% ----------------------------------------------------------
% Introduction
% ----------------------------------------------------------
\chapter{Introduction}

Modern society has been witnessing the rapid growth on the usage and variety of architectures of processors. Internet-of-things (IoT), Industry 4.0, and Artificial Intelligence are only examples of technological demands that contributed for this increasing market. The appearance of open architectures, like RISC-V, has also played an important role in this scenario. As the demand for customized Systems-on-Chip (SoC) increases, so does the need for efficient methods for processors verification. On top of that, these new applications can require very restrictive constraints like power consumption \TLSAY{power consumption and small area is not a constraint} and small area. In turn, these requirements call for highly optimized designs without giving up safety \TLSAY{Not every optimized design has to be "safe". You may accept a faulty design if it is not critical. Just think of how many times you had to restart your phone}. As a result, verification becomes even more important and also troublesome.\TLSAY{Why is verification becoming more troublesome if the design becomes more complex? Whats the problem with verification} 

One way to improve efficiency in the verification process is applying \TLREP{Formal Verification}{\textit{formal verification}(FV)} methods. Instead of using a hardware description language (HDL) \TLSAY{We introduce new terms by putting the new word in italic, only in the first instance and make sure you use a \~ in between the braces and the word: e.g.: \textit{hardware description language}~(HDL)}, such as VHDL and Verilog, to create test benches in order to find a fault in the design, process also known as “bug hunting”, \TLSAY{Parse error, rewrite this entire sentence} Formal Verification uses properties to check the correctness of the system. In this approach \TLSAY{What approach?}, the properties are descriptions of operations that represent the behaviour of the design. Although Formal Verification methods can guarantee the completeness \TLSAY{What is completeness of a design? Do you mean "a complete verification w.r.t. a specification?} of the design, i.e. the RTL implementation corresponds to the specifications, through a process known as Gap-free verification \TLSAY{Too much information. Whatis gap-free? Is it something people know? Take more time to elaborate}, the process of writing properties can be a very demanding and difficult step for the developer\TLSAY{Why?}. 

Another way to face verification complexity of processors is High-Level Synthesis (HLS) \TLSAY{HLS is not used for processors!}. This approach has evolved in the past years, and the number and quality of HLS tools has also increased. Despite of the advantages that HLS can offer, e.g. faster model implementation due to the higher level of abstraction of the implemented design, it is only applicable in certain domains, such as implementation of signal processing algorithms \cite{paper-pdd}. Therefore, for numerous cases \TLSAY{I'd say always?}, the Register Transfer Level (RTL) designs are derived from specifications in natural language and diagrams like Finite State Machines (FSM), and they are still used as verification reference, or “golden model”. This leaves the High-Level models, e.g. Electronic System Level (ESL) models, as prototypes used for validation of functional and non-functional requirements. In this case, there is no formal connection between RTL and High-Level implementation. Therefore, the is no guarantee that the RTL and ESL models are sound to each other. 
\TLSAY{Dont like this paragraph too much. You trying to point to the semantic gap, however, your red line does not make that much sense} 

In \cite{paper-pdd}, a new method for RTL design is proposed \TLREP{: Property-Driven Design (PDD)}{called \textit{Property-Driven Design}~(PDD)}  This method is inspired \TLREP{on}{by} \TLDEL{the} Test-Driven Development (TDD) \TLINS{, an} approach used in software development\TLINS{.} in contrast to the $V$-model, where testing is done closer to end of the design process. TDD brings testing to the start of the development process, \textit{shift left} \TLSAY{Shift left?}, and test cases are created even before the software product itself.\TLSAY{The previous sentences need rewriting} This allows to find bugs in the software at earlier stages of the development process. Therefore, correcting the bugs is cheaper than it would be at later stages. Similarly, PDD is intended to bring verification to earlier stages of the design process using \TLREP{properties}{formal verification}. In this method, a high-level description of the system is used to generate properties that should be refined concomitantly with the RTL implementation. In the end, an RTL design is achieved along with a set of properties that proves its correct behaviour. \TLREP{In addition}{Additionally}, the methodology guarantees that the achieved\TLSAY{achieved?} RTL is sound \TLSAY{What does sound mean here?} to the initial ESL model. As a result, both can be used as the golden model.

In order to apply the PDD methodology, the high-level model should be written with a subset of the SystemC \cite{systemC} library, called \textit{SystemC-PPA}. The authors in \cite{paper-pdd} created a tool, called DeSCAM \cite{descam}, that reads a \textit{SystemC-PPA} compliant model and automatically generates a set of properties\TLREP{ and}{. As help for the designer,} an RTL skeleton that can be used as a start point of the \textit{implementation-refinement} process \TLINS{can be generated}.

\TLINS{The methodology works well for ..., however ...}. A major drawback to the PDD method appears for pipelined processors \TLSAY{drawbacks dont appear}. The \textit{SystemC-PPA} model is implemented as a sequential CPU\TLSAY{CPU? Model?}. Therefore, the properties will inherit this sequential behaviour and it will not be able to reflect the concurrent pipeline behaviour. This will cause the hardware designer to have an extra effort to refine these properties to fit the pipeline, or to modify the \textit{SystemC-PPA} model to simulate the pipelined behaviour. In both cases, the extra effort for the hardware designer mitigates the advantages of the PDD method.

In this work, an algorithm to generate Pipeline Properties using the PDD method is proposed. The algorithm adds an extra step to the PDD process when dealing with pipelined processors design. The properties generated from the sequential \textit{SystemC-PPA} compliant model, from now on these properties will be referred as micro properties, are applied to the Pipeline Property Algorithm, which converts these micro properties into Pipeline Properties. Then, the hardware designer can start the \textit{implement-refine} process without extra work.

In order to evaluate the proposed Pipeline Algorithm, a case study was conducted with the RI5CY \TLSAY{Update, Reference to new design} core. This processor is an open-source implementation based on the RISC-V instruction set architecture (ISA), and it is powered by the PULP Platform \cite{pulp}. A \textit{SystemC-PPA} compliant model for the RI5CY processor was implemented, and the Extended for Pipeline PDD method was used to generate the Pipeline Properties. In this case study, the RTL implementation is already provided, and the Pipeline Properties should hold for this implementation after the refinement process. In addition, sequential properties were manually written, classical Formal Verification process, from the RTL model. These sequential properties are then used for comparison with the generated Pipeline Properties. 

\TLSAY{I like your red line, however, you need to more precise in your formulation.} 
\TLSAY{Maybe you split it into two section? Introduction and Motivation or something like that?}
\textcolor{red}{<<include the plugin that will be developed>>}
\textcolor{red}{<<STRUCTURE of the thesis...>>}
